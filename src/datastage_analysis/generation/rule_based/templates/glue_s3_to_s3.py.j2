"""
AWS Glue Job: {{ job_name }}
Generated by DataStage Migration Analyzer (rule-based)
Pattern: s3_to_s3
Generated at: {{ generated_at }}

Description: Reads data from S3, transforms, and writes to S3
Sources: {% for s in analysis.sources %}{{ s.name }}{% if not loop.last %}, {% endif %}{% endfor %}
Targets: {% for t in analysis.targets %}{{ t.name }}{% if not loop.last %}, {% endif %}{% endfor %}
"""

import sys
from awsglue.transforms import *
from awsglue.utils import getResolvedOptions
from pyspark.context import SparkContext
from awsglue.context import GlueContext
from awsglue.job import Job
from awsglue.dynamicframe import DynamicFrame
from pyspark.sql.functions import *


def main():
    # Get job arguments
    args = getResolvedOptions(sys.argv, [
        "JOB_NAME",
        "source_s3_path",
        "source_format",
        "target_s3_path",
        "target_format",
    ])

    # Initialize Glue context
    sc = SparkContext()
    glueContext = GlueContext(sc)
    spark = glueContext.spark_session
    job = Job(glueContext)
    job.init(args["JOB_NAME"], args)

    try:
        # ========================================
        # Read from S3
        # ========================================
{% for source in analysis.sources %}
        # Source: {{ source.name }} ({{ source.original_type }})
        source_format = args.get("source_format", "{{ source.format | default('csv') }}")

        df_{{ source.name | lower | replace(' ', '_') }} = glueContext.create_dynamic_frame.from_options(
            connection_type="s3",
            connection_options={
                "paths": [args["source_s3_path"]],
                "recurse": True,
            },
            format=source_format,
            format_options={
                "withHeader": True,
                "separator": ","
            } if source_format == "csv" else {},
            transformation_ctx="source_{{ loop.index }}_ctx"
        ).toDF()

        print(f"Read {{ source.name }}: {df_{{ source.name | lower | replace(' ', '_') }}.count()} rows")
{% endfor %}

        # ========================================
        # Transformations
        # ========================================
{% if analysis.transforms %}
{% for transform in analysis.transforms %}
        # Transform: {{ transform.name }} ({{ transform.original_type }})
        # TODO: Implement transformation logic
{% endfor %}
{% endif %}

        # Main dataframe for output
        df_output = df_{{ analysis.sources[0].name | lower | replace(' ', '_') if analysis.sources else 'input' }}

        # Example transformations (customize as needed):
        # df_output = df_output.withColumn("processed_date", current_timestamp())
        # df_output = df_output.filter(col("status") == "active")
        # df_output = df_output.dropDuplicates(["id"])

        # ========================================
        # Write to S3
        # ========================================
{% for target in analysis.targets %}
        # Target: {{ target.name }} ({{ target.original_type }})
        target_format = args.get("target_format", "{{ target.format | default('parquet') }}")

        output_frame = DynamicFrame.fromDF(df_output, glueContext, "output_frame")

        glueContext.write_dynamic_frame.from_options(
            frame=output_frame,
            connection_type="s3",
            connection_options={
                "path": args["target_s3_path"],
                "partitionKeys": [],  # Add partition keys if needed: ["year", "month"]
            },
            format=target_format,
            format_options={
                "compression": "snappy"
            } if target_format == "parquet" else {},
            transformation_ctx="target_{{ loop.index }}_ctx"
        )

        print(f"Wrote {{ target.name }}: {df_output.count()} rows to {args['target_s3_path']}")
{% endfor %}

        job.commit()
        print("Job completed successfully")

    except Exception as e:
        print(f"Job failed with error: {e}")
        import traceback
        traceback.print_exc()
        raise


if __name__ == "__main__":
    main()
