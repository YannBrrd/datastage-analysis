"""
LLM-Based Generator Implementation

Uses LLM to generate AWS Glue code for complex DataStage patterns.
Supports batch processing for similar jobs to reduce LLM calls.
"""

import logging
from typing import Dict, Any, Optional, List, Tuple
from pathlib import Path

from ..generator import GeneratedJob
from ...prediction.migration_predictor import MigrationPrediction, MigrationCategory
from ...llm.client import LLMClient, LLMResponse
from ...llm.optimization import BatchProcessor, PromptOptimizer

logger = logging.getLogger(__name__)

# Load prompts from files
PROMPTS_DIR = Path(__file__).parent / 'prompts'


class LLMGenerator:
    """
    Generates AWS Glue code using LLM for complex patterns.

    Used for:
    - SEMI-AUTO jobs: Enhances rule-based output for complex parts
    - MANUAL jobs: Generates skeleton with TODOs
    """

    def __init__(self, client: LLMClient):
        """
        Initialize the LLM generator.

        Args:
            client: LLM client instance
        """
        self.client = client
        self._system_prompt = self._load_prompt('system_prompt.txt')
        self.prompt_optimizer = PromptOptimizer()

        # Cache for template results
        self._template_cache: Dict[str, GeneratedJob] = {}

    def _load_prompt(self, filename: str) -> str:
        """Load prompt from file."""
        prompt_path = PROMPTS_DIR / filename
        if prompt_path.exists():
            return prompt_path.read_text()
        return self._get_default_prompt(filename)

    def _get_default_prompt(self, prompt_type: str) -> str:
        """Get default prompt if file not found."""
        if 'system' in prompt_type:
            return """You are an expert in migrating IBM DataStage ETL jobs to AWS Glue.
You write clean, efficient PySpark code following AWS Glue best practices.
Always include error handling, logging, and comments.
Follow the AWS Glue programming guide for DynamicFrames and transformations."""
        return ""

    def enhance(
        self,
        base_result: GeneratedJob,
        prediction: MigrationPrediction,
        structure: Dict
    ) -> GeneratedJob:
        """
        Enhance rule-based generated code with LLM for complex parts.

        Args:
            base_result: Result from rule-based generator
            prediction: Migration prediction
            structure: Job structure

        Returns:
            Enhanced GeneratedJob
        """
        # Identify what needs LLM enhancement
        needs_enhancement = []

        if 'complex_transform' in ' '.join(prediction.automation_blockers).lower():
            needs_enhancement.append('transforms')
        if 'custom' in ' '.join(prediction.automation_blockers).lower():
            needs_enhancement.append('custom_stages')
        if 'sql' in ' '.join(prediction.automation_blockers).lower():
            needs_enhancement.append('sql_conversion')

        if not needs_enhancement:
            return base_result

        # Build enhancement prompt
        prompt = self._build_enhancement_prompt(
            base_result.glue_script,
            structure,
            needs_enhancement
        )

        try:
            response = self.client.complete(
                prompt=prompt,
                system=self._system_prompt,
                temperature=0.2,
                max_tokens=4096,
            )

            # Parse enhanced code from response
            enhanced_script = self._extract_code(response.content)

            if enhanced_script:
                base_result.glue_script = enhanced_script
                base_result.llm_tokens_used = response.total_tokens

            return base_result

        except Exception as e:
            logger.error(f"LLM enhancement failed: {e}")
            base_result.warnings.append(f"LLM enhancement failed: {e}")
            return base_result

    def generate_skeleton(
        self,
        prediction: MigrationPrediction,
        structure: Dict
    ) -> GeneratedJob:
        """
        Generate skeleton code with TODOs for MANUAL jobs.

        Args:
            prediction: Migration prediction
            structure: Job structure

        Returns:
            GeneratedJob with skeleton code
        """
        prompt = self._build_skeleton_prompt(prediction, structure)

        try:
            response = self.client.complete(
                prompt=prompt,
                system=self._system_prompt,
                temperature=0.3,  # Slightly higher for creativity
                max_tokens=6000,
            )

            glue_script = self._extract_code(response.content)

            if not glue_script:
                glue_script = f'''"""
AWS Glue Job Skeleton: {prediction.job_name}
Generated by LLM - Requires manual completion

Category: MANUAL
Risk Level: {prediction.risk_level.value}
Blockers: {', '.join(prediction.automation_blockers)}

LLM Response:
{response.content[:2000]}...
"""

# TODO: Implement this job manually
# The following DataStage components need manual migration:
# {chr(10).join(f"# - {b}" for b in prediction.automation_blockers)}

raise NotImplementedError("This job requires manual implementation")
'''

            return GeneratedJob(
                job_name=prediction.job_name,
                category=prediction.category,
                success=True,
                glue_script=glue_script,
                generator_type="llm_based",
                llm_tokens_used=response.total_tokens,
                warnings=["Generated skeleton - requires manual review and completion"],
            )

        except Exception as e:
            logger.error(f"LLM skeleton generation failed: {e}")
            return GeneratedJob(
                job_name=prediction.job_name,
                category=prediction.category,
                success=False,
                error=f"LLM generation failed: {e}",
                generator_type="llm_based",
            )

    def _build_enhancement_prompt(
        self,
        base_script: str,
        structure: Dict,
        enhancement_areas: list
    ) -> str:
        """Build prompt for enhancing existing code."""
        stages_info = self._format_stages(structure)

        return f"""I have a partially generated AWS Glue script that needs enhancement.
The script was generated from a DataStage job but needs improvements in these areas:
{', '.join(enhancement_areas)}

Current script:
```python
{base_script}
```

DataStage job structure:
{stages_info}

Please enhance the script to properly handle the identified areas.
Focus on:
1. Proper error handling
2. Efficient PySpark transformations
3. Correct Glue DynamicFrame usage
4. Logging and monitoring

Return ONLY the enhanced Python code, no explanations."""

    def _build_skeleton_prompt(
        self,
        prediction: MigrationPrediction,
        structure: Dict
    ) -> str:
        """Build prompt for skeleton generation."""
        stages_info = self._format_stages(structure)

        return f"""Generate an AWS Glue job skeleton for migrating a DataStage job.

Job Name: {prediction.job_name}
Category: MANUAL (requires significant manual work)
Risk Level: {prediction.risk_level.value}

Automation Blockers (why this needs manual work):
{chr(10).join(f"- {b}" for b in prediction.automation_blockers)}

DataStage Job Structure:
{stages_info}

Generate a Glue Python script that:
1. Has the basic structure (imports, main function, GlueContext setup)
2. Includes TODO comments for each part that needs manual implementation
3. Documents what each DataStage component was supposed to do
4. Includes placeholder functions for complex logic
5. Has proper error handling structure

Return ONLY the Python code, no explanations."""

    def _format_stages(self, structure: Dict) -> str:
        """Format stages for prompt."""
        stages = structure.get('stages', [])
        if not stages:
            return "No stages information available"

        lines = []
        for stage in stages[:20]:  # Limit to avoid token overflow
            stage_type = stage.get('type', 'Unknown')
            stage_name = stage.get('name', 'unnamed')
            props = stage.get('properties', {})
            lines.append(f"- {stage_name} ({stage_type})")
            if props:
                for k, v in list(props.items())[:5]:
                    lines.append(f"    {k}: {str(v)[:100]}")

        if len(stages) > 20:
            lines.append(f"... and {len(stages) - 20} more stages")

        return '\n'.join(lines)

    def _extract_code(self, response: str) -> Optional[str]:
        """Extract Python code from LLM response."""
        # Try to find code blocks
        if '```python' in response:
            start = response.find('```python') + 9
            end = response.find('```', start)
            if end > start:
                return response[start:end].strip()

        if '```' in response:
            start = response.find('```') + 3
            end = response.find('```', start)
            if end > start:
                code = response[start:end].strip()
                # Skip language identifier if present
                if code.startswith(('python', 'py')):
                    code = code.split('\n', 1)[1] if '\n' in code else ''
                return code.strip()

        # If no code blocks, check if response looks like Python
        if 'import ' in response and 'def ' in response:
            return response.strip()

        return None

    # =========================================================================
    # Batch Processing Methods
    # =========================================================================

    def generate_for_batch(
        self,
        template_job: str,
        template_prediction: MigrationPrediction,
        template_structure: Dict,
        similar_jobs: List[Tuple[str, MigrationPrediction, Dict]],
    ) -> Dict[str, GeneratedJob]:
        """
        Generate code for a batch of similar jobs.

        Uses the template job for full LLM generation, then applies
        variations for similar jobs with minimal LLM calls.

        Args:
            template_job: Name of template job
            template_prediction: Prediction for template job
            template_structure: Structure of template job
            similar_jobs: List of (job_name, prediction, structure) tuples

        Returns:
            Dict mapping job names to GeneratedJob results
        """
        results = {}

        # Step 1: Generate full code for template job
        logger.info(f"Generating template job: {template_job}")
        template_result = self._generate_template(
            template_prediction,
            template_structure
        )
        results[template_job] = template_result
        self._template_cache[template_job] = template_result

        if not template_result.success:
            # Template failed, fall back to individual generation
            logger.warning(f"Template generation failed, using individual generation")
            for job_name, pred, struct in similar_jobs:
                results[job_name] = self.generate_skeleton(pred, struct)
            return results

        # Step 2: Apply variations for similar jobs
        logger.info(f"Applying variations for {len(similar_jobs)} similar jobs")

        for job_name, prediction, structure in similar_jobs:
            if job_name == template_job:
                continue

            variation_result = self._apply_variation(
                template_result,
                template_structure,
                job_name,
                prediction,
                structure
            )
            results[job_name] = variation_result

        return results

    def _generate_template(
        self,
        prediction: MigrationPrediction,
        structure: Dict
    ) -> GeneratedJob:
        """Generate full code for template job."""
        prompt = self._build_template_prompt(prediction, structure)
        optimized_prompt = self.prompt_optimizer.optimize(prompt)

        try:
            response = self.client.complete(
                prompt=optimized_prompt,
                system=self._system_prompt,
                temperature=0.2,
                max_tokens=6000,
            )

            glue_script = self._extract_code(response.content)

            if not glue_script:
                raise ValueError("Could not extract code from LLM response")

            # Also generate terraform
            terraform = self._generate_terraform_for_template(prediction)

            return GeneratedJob(
                job_name=prediction.job_name,
                category=prediction.category,
                success=True,
                glue_script=glue_script,
                terraform=terraform,
                generator_type="llm_based_template",
                llm_tokens_used=response.total_tokens,
                warnings=["Template job - verify before applying to cluster"],
            )

        except Exception as e:
            logger.error(f"Template generation failed: {e}")
            return GeneratedJob(
                job_name=prediction.job_name,
                category=prediction.category,
                success=False,
                error=f"Template generation failed: {e}",
                generator_type="llm_based_template",
            )

    def _build_template_prompt(
        self,
        prediction: MigrationPrediction,
        structure: Dict
    ) -> str:
        """Build comprehensive prompt for template generation."""
        stages_info = self._format_stages(structure)

        return f"""Generate a complete AWS Glue job for this DataStage migration.
This job will serve as a TEMPLATE for {prediction.job_name} and similar jobs in its cluster.

Job Name: {prediction.job_name}
Category: {prediction.category.value}
Risk Level: {prediction.risk_level.value}

Blockers requiring attention:
{chr(10).join(f"- {b}" for b in prediction.automation_blockers)}

DataStage Job Structure:
{stages_info}

Requirements:
1. Complete, working Glue Python script
2. Use DynamicFrames where appropriate
3. Include proper error handling with try/except
4. Add logging statements for monitoring
5. Include job arguments for parameterization (source tables, target paths, etc.)
6. Use connection names as job arguments so they can be easily changed per environment
7. Add comments explaining the logic

IMPORTANT: Make the code parameterized so similar jobs can reuse this template
by just changing job arguments (table names, file paths, etc.)

Return ONLY the Python code."""

    def _generate_terraform_for_template(self, prediction: MigrationPrediction) -> str:
        """Generate basic Terraform for the template job."""
        job_name = prediction.job_name.lower().replace(' ', '_')

        return f'''# Terraform configuration for {prediction.job_name}
# Template job - adjust parameters for similar jobs in cluster

resource "aws_glue_job" "{job_name}" {{
  name     = "{prediction.job_name}"
  role_arn = var.glue_role_arn

  command {{
    name            = "glueetl"
    script_location = "s3://${{var.scripts_bucket}}/glue_jobs/{job_name}.py"
    python_version  = "3"
  }}

  default_arguments = {{
    "--job-language"          = "python"
    "--enable-metrics"        = "true"
    "--enable-continuous-cloudwatch-log" = "true"
    "--enable-glue-datacatalog" = "true"
    # Add job-specific arguments below
  }}

  glue_version      = "4.0"
  worker_type       = "G.1X"
  number_of_workers = 2

  tags = {{
    Environment     = var.environment
    MigrationSource = "DataStage"
    MigrationBatch  = var.batch_name
  }}
}}
'''

    def _apply_variation(
        self,
        template_result: GeneratedJob,
        template_structure: Dict,
        job_name: str,
        prediction: MigrationPrediction,
        structure: Dict
    ) -> GeneratedJob:
        """
        Apply template to a similar job with variations.

        For minor differences, uses string replacement.
        For significant differences, makes a lightweight LLM call.
        """
        # Analyze differences
        differences = self._find_structural_differences(
            template_structure, structure
        )

        if not differences or self._can_apply_simple_variation(differences):
            # Simple variation - no LLM needed
            return self._apply_simple_variation(
                template_result, job_name, prediction, differences
            )
        else:
            # Need LLM for complex variation
            return self._apply_llm_variation(
                template_result, job_name, prediction, structure, differences
            )

    def _find_structural_differences(
        self,
        template: Dict,
        job: Dict
    ) -> Dict[str, Any]:
        """Find differences between template and job structures."""
        diffs = {
            'added_stages': [],
            'removed_stages': [],
            'property_changes': {},
        }

        t_stages = {s.get('name'): s for s in template.get('stages', [])}
        j_stages = {s.get('name'): s for s in job.get('stages', [])}

        diffs['added_stages'] = list(set(j_stages.keys()) - set(t_stages.keys()))
        diffs['removed_stages'] = list(set(t_stages.keys()) - set(j_stages.keys()))

        # Find property differences in common stages
        common = set(t_stages.keys()) & set(j_stages.keys())
        for name in common:
            t_props = t_stages[name].get('properties', {})
            j_props = j_stages[name].get('properties', {})

            changes = {}
            for key in set(t_props.keys()) | set(j_props.keys()):
                if t_props.get(key) != j_props.get(key):
                    changes[key] = {
                        'from': t_props.get(key),
                        'to': j_props.get(key)
                    }

            if changes:
                diffs['property_changes'][name] = changes

        return diffs

    def _can_apply_simple_variation(self, differences: Dict) -> bool:
        """Check if differences can be handled without LLM."""
        # Simple if: no structural changes, only property changes
        if differences['added_stages'] or differences['removed_stages']:
            return False

        # Check if property changes are simple (table names, file paths, etc.)
        simple_props = {'table', 'file', 'filename', 'path', 'connection',
                       'database', 'schema', 'query', 'sql'}

        for stage, changes in differences['property_changes'].items():
            for prop in changes.keys():
                prop_lower = prop.lower()
                if not any(s in prop_lower for s in simple_props):
                    return False

        return True

    def _apply_simple_variation(
        self,
        template_result: GeneratedJob,
        job_name: str,
        prediction: MigrationPrediction,
        differences: Dict
    ) -> GeneratedJob:
        """Apply simple string-based variation to template."""
        script = template_result.glue_script

        # Replace job name
        old_name = template_result.job_name
        script = script.replace(f'"{old_name}"', f'"{job_name}"')
        script = script.replace(f"'{old_name}'", f"'{job_name}'")

        # Apply property changes as string replacements
        for stage, changes in differences['property_changes'].items():
            for prop, change in changes.items():
                if change['from'] and change['to']:
                    script = script.replace(str(change['from']), str(change['to']))

        # Adjust terraform
        terraform = template_result.terraform
        if terraform:
            terraform = terraform.replace(old_name, job_name)
            terraform = terraform.replace(
                old_name.lower().replace(' ', '_'),
                job_name.lower().replace(' ', '_')
            )

        return GeneratedJob(
            job_name=job_name,
            category=prediction.category,
            success=True,
            glue_script=script,
            terraform=terraform,
            generator_type="batch_variation",
            llm_tokens_used=0,  # No LLM call!
            warnings=["Generated from template - verify specific values"],
        )

    def _apply_llm_variation(
        self,
        template_result: GeneratedJob,
        job_name: str,
        prediction: MigrationPrediction,
        structure: Dict,
        differences: Dict
    ) -> GeneratedJob:
        """Apply LLM-assisted variation for complex differences."""
        prompt = f"""Adapt this AWS Glue template code for a similar job.

Original job: {template_result.job_name}
Target job: {job_name}

Structural differences:
- Added stages: {', '.join(differences['added_stages']) or 'none'}
- Removed stages: {', '.join(differences['removed_stages']) or 'none'}
- Property changes: {len(differences['property_changes'])} stages modified

Template code:
```python
{template_result.glue_script[:3000]}
```

Please adapt the code for the target job, incorporating the differences.
Focus on:
1. Adjusting for added/removed stages
2. Updating property values
3. Keeping the same structure and patterns

Return ONLY the adapted Python code."""

        try:
            response = self.client.complete(
                prompt=self.prompt_optimizer.optimize(prompt),
                system=self._system_prompt,
                temperature=0.2,
                max_tokens=4000,
            )

            script = self._extract_code(response.content)

            if not script:
                # Fall back to simple variation
                return self._apply_simple_variation(
                    template_result, job_name, prediction, differences
                )

            return GeneratedJob(
                job_name=job_name,
                category=prediction.category,
                success=True,
                glue_script=script,
                terraform=template_result.terraform.replace(
                    template_result.job_name, job_name
                ) if template_result.terraform else None,
                generator_type="batch_llm_variation",
                llm_tokens_used=response.total_tokens,
                warnings=["Generated via LLM variation - verify complex changes"],
            )

        except Exception as e:
            logger.error(f"LLM variation failed: {e}")
            # Fall back to simple variation
            return self._apply_simple_variation(
                template_result, job_name, prediction, differences
            )
