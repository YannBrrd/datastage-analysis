"""
LLM-Based Generator Implementation

Uses LLM to generate AWS Glue code for complex DataStage patterns.
"""

import logging
from typing import Dict, Any, Optional
from pathlib import Path

from ..generator import GeneratedJob
from ...prediction.migration_predictor import MigrationPrediction, MigrationCategory
from ...llm.client import LLMClient, LLMResponse

logger = logging.getLogger(__name__)

# Load prompts from files
PROMPTS_DIR = Path(__file__).parent / 'prompts'


class LLMGenerator:
    """
    Generates AWS Glue code using LLM for complex patterns.

    Used for:
    - SEMI-AUTO jobs: Enhances rule-based output for complex parts
    - MANUAL jobs: Generates skeleton with TODOs
    """

    def __init__(self, client: LLMClient):
        """
        Initialize the LLM generator.

        Args:
            client: LLM client instance
        """
        self.client = client
        self._system_prompt = self._load_prompt('system_prompt.txt')

    def _load_prompt(self, filename: str) -> str:
        """Load prompt from file."""
        prompt_path = PROMPTS_DIR / filename
        if prompt_path.exists():
            return prompt_path.read_text()
        return self._get_default_prompt(filename)

    def _get_default_prompt(self, prompt_type: str) -> str:
        """Get default prompt if file not found."""
        if 'system' in prompt_type:
            return """You are an expert in migrating IBM DataStage ETL jobs to AWS Glue.
You write clean, efficient PySpark code following AWS Glue best practices.
Always include error handling, logging, and comments.
Follow the AWS Glue programming guide for DynamicFrames and transformations."""
        return ""

    def enhance(
        self,
        base_result: GeneratedJob,
        prediction: MigrationPrediction,
        structure: Dict
    ) -> GeneratedJob:
        """
        Enhance rule-based generated code with LLM for complex parts.

        Args:
            base_result: Result from rule-based generator
            prediction: Migration prediction
            structure: Job structure

        Returns:
            Enhanced GeneratedJob
        """
        # Identify what needs LLM enhancement
        needs_enhancement = []

        if 'complex_transform' in ' '.join(prediction.automation_blockers).lower():
            needs_enhancement.append('transforms')
        if 'custom' in ' '.join(prediction.automation_blockers).lower():
            needs_enhancement.append('custom_stages')
        if 'sql' in ' '.join(prediction.automation_blockers).lower():
            needs_enhancement.append('sql_conversion')

        if not needs_enhancement:
            return base_result

        # Build enhancement prompt
        prompt = self._build_enhancement_prompt(
            base_result.glue_script,
            structure,
            needs_enhancement
        )

        try:
            response = self.client.complete(
                prompt=prompt,
                system=self._system_prompt,
                temperature=0.2,
                max_tokens=4096,
            )

            # Parse enhanced code from response
            enhanced_script = self._extract_code(response.content)

            if enhanced_script:
                base_result.glue_script = enhanced_script
                base_result.llm_tokens_used = response.total_tokens

            return base_result

        except Exception as e:
            logger.error(f"LLM enhancement failed: {e}")
            base_result.warnings.append(f"LLM enhancement failed: {e}")
            return base_result

    def generate_skeleton(
        self,
        prediction: MigrationPrediction,
        structure: Dict
    ) -> GeneratedJob:
        """
        Generate skeleton code with TODOs for MANUAL jobs.

        Args:
            prediction: Migration prediction
            structure: Job structure

        Returns:
            GeneratedJob with skeleton code
        """
        prompt = self._build_skeleton_prompt(prediction, structure)

        try:
            response = self.client.complete(
                prompt=prompt,
                system=self._system_prompt,
                temperature=0.3,  # Slightly higher for creativity
                max_tokens=6000,
            )

            glue_script = self._extract_code(response.content)

            if not glue_script:
                glue_script = f'''"""
AWS Glue Job Skeleton: {prediction.job_name}
Generated by LLM - Requires manual completion

Category: MANUAL
Risk Level: {prediction.risk_level.value}
Blockers: {', '.join(prediction.automation_blockers)}

LLM Response:
{response.content[:2000]}...
"""

# TODO: Implement this job manually
# The following DataStage components need manual migration:
# {chr(10).join(f"# - {b}" for b in prediction.automation_blockers)}

raise NotImplementedError("This job requires manual implementation")
'''

            return GeneratedJob(
                job_name=prediction.job_name,
                category=prediction.category,
                success=True,
                glue_script=glue_script,
                generator_type="llm_based",
                llm_tokens_used=response.total_tokens,
                warnings=["Generated skeleton - requires manual review and completion"],
            )

        except Exception as e:
            logger.error(f"LLM skeleton generation failed: {e}")
            return GeneratedJob(
                job_name=prediction.job_name,
                category=prediction.category,
                success=False,
                error=f"LLM generation failed: {e}",
                generator_type="llm_based",
            )

    def _build_enhancement_prompt(
        self,
        base_script: str,
        structure: Dict,
        enhancement_areas: list
    ) -> str:
        """Build prompt for enhancing existing code."""
        stages_info = self._format_stages(structure)

        return f"""I have a partially generated AWS Glue script that needs enhancement.
The script was generated from a DataStage job but needs improvements in these areas:
{', '.join(enhancement_areas)}

Current script:
```python
{base_script}
```

DataStage job structure:
{stages_info}

Please enhance the script to properly handle the identified areas.
Focus on:
1. Proper error handling
2. Efficient PySpark transformations
3. Correct Glue DynamicFrame usage
4. Logging and monitoring

Return ONLY the enhanced Python code, no explanations."""

    def _build_skeleton_prompt(
        self,
        prediction: MigrationPrediction,
        structure: Dict
    ) -> str:
        """Build prompt for skeleton generation."""
        stages_info = self._format_stages(structure)

        return f"""Generate an AWS Glue job skeleton for migrating a DataStage job.

Job Name: {prediction.job_name}
Category: MANUAL (requires significant manual work)
Risk Level: {prediction.risk_level.value}

Automation Blockers (why this needs manual work):
{chr(10).join(f"- {b}" for b in prediction.automation_blockers)}

DataStage Job Structure:
{stages_info}

Generate a Glue Python script that:
1. Has the basic structure (imports, main function, GlueContext setup)
2. Includes TODO comments for each part that needs manual implementation
3. Documents what each DataStage component was supposed to do
4. Includes placeholder functions for complex logic
5. Has proper error handling structure

Return ONLY the Python code, no explanations."""

    def _format_stages(self, structure: Dict) -> str:
        """Format stages for prompt."""
        stages = structure.get('stages', [])
        if not stages:
            return "No stages information available"

        lines = []
        for stage in stages[:20]:  # Limit to avoid token overflow
            stage_type = stage.get('type', 'Unknown')
            stage_name = stage.get('name', 'unnamed')
            props = stage.get('properties', {})
            lines.append(f"- {stage_name} ({stage_type})")
            if props:
                for k, v in list(props.items())[:5]:
                    lines.append(f"    {k}: {str(v)[:100]}")

        if len(stages) > 20:
            lines.append(f"... and {len(stages) - 20} more stages")

        return '\n'.join(lines)

    def _extract_code(self, response: str) -> Optional[str]:
        """Extract Python code from LLM response."""
        # Try to find code blocks
        if '```python' in response:
            start = response.find('```python') + 9
            end = response.find('```', start)
            if end > start:
                return response[start:end].strip()

        if '```' in response:
            start = response.find('```') + 3
            end = response.find('```', start)
            if end > start:
                code = response[start:end].strip()
                # Skip language identifier if present
                if code.startswith(('python', 'py')):
                    code = code.split('\n', 1)[1] if '\n' in code else ''
                return code.strip()

        # If no code blocks, check if response looks like Python
        if 'import ' in response and 'def ' in response:
            return response.strip()

        return None
